{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429d7569-688e-4513-bc81-2bbecb5fa5ca",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This file focuses on organizing and generating higher-level topic labels from a set of subtopics (topic clsusters) using hierarchical clustering and natural language processing (NLP). The main steps involve embedding subtopic labels, clustering these embeddings, and generating human-readable topic labels for higher topic interpretation.\n",
    "\n",
    "### Main Components\n",
    "1. **Data Loading and Preparation**:\n",
    "   - The `load_and_merge_datasets` function loads multiple datasets and merges them into a single DataFrame, filtering out any records without a valid topic.\n",
    "\n",
    "2. **Embeddings**:\n",
    "   - The notebook utilizes the `SentenceTransformer` model to encode subtopics into vector representations (embeddings). This is handled by the `compute_embeddings` function.\n",
    "\n",
    "3. **Clustering**:\n",
    "   - **Hierarchical Clustering**:\n",
    "     - The `perform_clustering` function performs hierarchical clustering on the topic embeddings using the Ward method. This results in a dendrogram that visualizes the relationships between subtopics.\n",
    "   - **Cluster Assignment**:\n",
    "     - The `assign_cluster_labels` function assigns each subtopic to a cluster based on a specified cut height in the dendrogram.\n",
    "\n",
    "4. **Higher-Level Topic Generation**:\n",
    "   - **Grouping Subtopics**:\n",
    "     - `group_subtopics_by_cluster` aggregates subtopics within each cluster, preparing the data for generating higher-level topic labels.\n",
    "   - **Label Generation with Together AI**:\n",
    "     - The `generate_topic_label_together` function leverages a Together AI LLM to create concise and human-readable labels that represent each cluster.\n",
    "   - **Finding Representative Documents**:\n",
    "     - `find_representative_document` identifies a representative document for each cluster by finding the embedding that is most similar to the cluster centroid.\n",
    "\n",
    "5. **Final Processing**:\n",
    "   - The `process_clusters` function processes each cluster, generating a higher-level topic label and selecting a representative document for it.\n",
    "   - The final results are saved to a CSV file using the `save_results` function.\n",
    "\n",
    "6. **Main Workflow**:\n",
    "   - The `main` function orchestrates the entire workflow, starting from initializing the API client and loading data to clustering, topic label generation, and saving results.\n",
    "\n",
    "### Additional Details\n",
    "- The notebook uses the `SentenceTransformer` model (`all-MiniLM-L6-v2`) for generating embeddings.\n",
    "- It performs hierarchical clustering using the Ward method and determines cluster labels based on a specified cut height in the dendrogram. (baed on heuristics, 1.2 is chosen)\n",
    "- The Together AI LLM is used to generate human-readable, higher-level topic labels.\n",
    "\n",
    "This process aids in transforming subtopics into broader, more interpretable categories, making it easier to understand the content and structure of large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f102f-0797-4a65-805f-dc0f5abdb389",
   "metadata": {},
   "source": [
    "1. **Data Loading and Preparation**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a1a258-b2b4-46ec-913c-34f257308663",
   "metadata": {},
   "source": [
    "**First Step - Second Level Topic Knowledge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1228b7c0-1113-40dd-b1cb-b232b5a4c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two datasets\n",
    "first_step_df = pd.read_csv('First_Step_BERTopic_topic_info_labelled.csv')\n",
    "higher_level_topics_df = pd.read_csv('Hierchical_Topics_Second_Level-Topics.csv')\n",
    "\n",
    "higher_level_topics_df.rename(columns={'Higher_Topic_Label': 'Second_Level_Topic_Label'}, inplace=True)\n",
    "higher_level_topics_df\n",
    "\n",
    "# Function to clean and split the topics\n",
    "def clean_and_split_topics(topic_str):\n",
    "    # Remove quotes and split by commas, then strip any extra spaces\n",
    "    topics = [topic.strip().replace('\"', '') for topic in topic_str.split(',')]\n",
    "    return topics\n",
    "\n",
    "\n",
    "# Apply the cleaning function to the 'Human_Readable_Topic' column\n",
    "first_step_df['Human_Readable_Topic'] = first_step_df['Human_Readable_Topic'].str.replace('\"', '', regex=False)\n",
    "higher_level_topics_df['Human_Readable_Topic'] = higher_level_topics_df['Human_Readable_Topic'].apply(clean_and_split_topics)\n",
    "\n",
    "# Explode the 'Human_Readable_Topic' to create a row for each topic\n",
    "higher_level_topics_df = higher_level_topics_df.explode('Human_Readable_Topic')\n",
    "\n",
    "first_step_df\n",
    "higher_level_topics_df\n",
    "# Merge the two datasets on the cleaned 'Human_Readable_Topic' column\n",
    "merged_df = pd.merge(first_step_df, higher_level_topics_df[['Human_Readable_Topic', 'Second_Level_Topic_Label']], \n",
    "                     on='Human_Readable_Topic', how='left')\n",
    "merged_df\n",
    "# # Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv('BERTopic_First_Step_Second_Level_Topic_Knowledge.csv', index=False)\n",
    "\n",
    "# print(\"Merging completed and the result is saved as 'BERTopic_First_Step_Second_Level_Topic_Knowledge.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af6cf-ef49-413a-ae19-7be8a15a5dc6",
   "metadata": {},
   "source": [
    "<!-- This is the code, if the regular String based matching doesn't work!!!! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e7a1e4-db7a-40a8-95f1-4156d5988858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed and the result is saved as 'BERTopic_First_Step_Second_Level_Topic_Knowledge_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the datasets\n",
    "first_step_df = pd.read_csv('First_Step_BERTopic_topic_info_labelled.csv')\n",
    "higher_level_topics_df = pd.read_csv('Hierchical_Topics_Second_Level-Topics.csv')\n",
    "\n",
    "# Rename column for consistency\n",
    "higher_level_topics_df.rename(columns={'Higher_Topic_Label': 'Second_Level_Topic_Label'}, inplace=True)\n",
    "\n",
    "# Function to clean and split the topics\n",
    "def clean_topic_string(topic_str):\n",
    "    # Remove quotes and extra spaces from the string\n",
    "    cleaned_str = topic_str.replace('\"', '').strip()\n",
    "    return cleaned_str\n",
    "\n",
    "# Apply the cleaning function to both datasets' Human_Readable_Topic column\n",
    "first_step_df['Human_Readable_Topic'] = first_step_df['Human_Readable_Topic'].apply(clean_topic_string)\n",
    "higher_level_topics_df['Human_Readable_Topic'] = higher_level_topics_df['Human_Readable_Topic'].apply(clean_topic_string)\n",
    "\n",
    "# Combine all human-readable topics for vectorization\n",
    "all_topics_cleaned = pd.concat([first_step_df['Human_Readable_Topic'], higher_level_topics_df['Human_Readable_Topic']])\n",
    "\n",
    "# Vectorize the cleaned topics using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix_cleaned = vectorizer.fit_transform(all_topics_cleaned)\n",
    "\n",
    "# Split the cleaned TF-IDF matrix back into the two parts\n",
    "first_step_tfidf_cleaned = tfidf_matrix_cleaned[:len(first_step_df)]\n",
    "higher_level_tfidf_cleaned = tfidf_matrix_cleaned[len(first_step_df):]\n",
    "\n",
    "# Calculate cosine similarity between each cleaned topic in first_step_df and all cleaned topics in higher_level_topics_df\n",
    "similarity_matrix_cleaned = cosine_similarity(first_step_tfidf_cleaned, higher_level_tfidf_cleaned)\n",
    "\n",
    "# Find the index of the highest similarity for each topic\n",
    "best_match_indices_cleaned = similarity_matrix_cleaned.argmax(axis=1)\n",
    "\n",
    "# Get the best matching topics and their corresponding labels\n",
    "first_step_df['Matched_Topic'] = higher_level_topics_df.iloc[best_match_indices_cleaned]['Human_Readable_Topic'].values\n",
    "first_step_df['Second_Level_Topic_Label'] = higher_level_topics_df.iloc[best_match_indices_cleaned]['Second_Level_Topic_Label'].values\n",
    "\n",
    "# Save the cleaned and merged dataframe to a new CSV file\n",
    "first_step_df.to_csv('BERTopic_First_Step_Second_Level_Topic_Knowledge.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as 'BERTopic_First_Step_Second_Level_Topic_Knowledge_cleaned.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e841a16-0118-4f63-a325-3e6187bcfea7",
   "metadata": {},
   "source": [
    "First Step - Third Level Topic Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b45340-29c6-42d8-b64b-eb7a7da23528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed and the result is saved as BERTopic_First_Step_Second_Level_Topic_Knowledge.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "first_step_df = pd.read_csv('BERTopic_First_Step_Second_Level_Topic_Knowledge.csv')\n",
    "highest_level_topics_df = pd.read_csv('Hierchical_Topics_Third_Level-Topics.csv')\n",
    "\n",
    "# Function to clean and split the 'Higher_Topic_Label' column\n",
    "def clean_and_split_labels(label_str):\n",
    "    # Split by commas and strip any extra spaces\n",
    "    labels = [label.strip() for label in label_str.split(';')]\n",
    "    return labels\n",
    "\n",
    "# Apply the cleaning and splitting function to the 'Higher_Topic_Label' column\n",
    "highest_level_topics_df['Second_Level_Topic_Label'] = highest_level_topics_df['Second_Level_Topic_Label'].apply(clean_and_split_labels)\n",
    "\n",
    "# Explode the 'Higher_Topic_Label' to create a row for each label\n",
    "highest_level_topics_df = highest_level_topics_df.explode('Second_Level_Topic_Label')\n",
    "\n",
    "# Merge the first step dataset with the highest level topics based on 'Higher_Topic_Label'\n",
    "final_merged_df = pd.merge(first_step_df, highest_level_topics_df[['Second_Level_Topic_Label', 'Highest_Topic_Label']], \n",
    "                           on='Second_Level_Topic_Label', how='left')\n",
    "\n",
    "# Save the final merged dataframe to a new CSV file\n",
    "final_merged_df.to_csv('BERTopic_First_Step_Third_Level_Topic_Knowledge.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as BERTopic_First_Step_Second_Level_Topic_Knowledge.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b5914-fa10-4ac3-85af-da24112eb13b",
   "metadata": {},
   "source": [
    "First Step - Final Topic Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e11011-d3e9-49c6-ad4a-dc53a7585ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed and the result is saved as 'First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "first_step_final_df = pd.read_csv('BERTopic_First_Step_Third_Level_Topic_Knowledge.csv')\n",
    "final_highest_level_topics_df = pd.read_csv('final_highest_level_topic_labels_with_representatives.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Function to split the 'Highest_Topic_Label' based on semicolons or commas, handle NaN values\n",
    "def split_labels(label_str):\n",
    "    if isinstance(label_str, str):  # Check if the label_str is a string\n",
    "        # Split by semicolon or comma and strip any extra spaces\n",
    "        labels = [label.strip() for label in label_str.split(',')]\n",
    "    else:\n",
    "        labels = [None]  # Return a list with None if label_str is not a string\n",
    "    return labels\n",
    "\n",
    "# Apply the splitting function to the 'Highest_Topic_Label' in the first dataset\n",
    "first_step_final_df['Highest_Topic_Label_Split'] = first_step_final_df['Highest_Topic_Label'].apply(split_labels)\n",
    "\n",
    "# Explode the first dataframe to have one row per label\n",
    "first_step_final_df = first_step_final_df.explode('Highest_Topic_Label_Split')\n",
    "\n",
    "# Explode the final_highest_level_topics_df based on 'Highest_Topic_Label' for proper matching\n",
    "final_highest_level_topics_df['Highest_Topic_Label_Split'] = final_highest_level_topics_df['Highest_Topic_Label'].apply(split_labels)\n",
    "final_highest_level_topics_df = final_highest_level_topics_df.explode('Highest_Topic_Label_Split')\n",
    "\n",
    "# Merge the exploded first dataset with the final highest level topics on 'Highest_Topic_Label_Split'\n",
    "final_merged_df = pd.merge(first_step_final_df, final_highest_level_topics_df[['Highest_Topic_Label_Split', 'Final_Label']], \n",
    "                           left_on='Highest_Topic_Label_Split', right_on='Highest_Topic_Label_Split', how='left')\n",
    "\n",
    "# Drop the auxiliary column used for merging\n",
    "final_merged_df.drop(columns=['Highest_Topic_Label_Split'], inplace=True)\n",
    "\n",
    "# Save the final merged dataframe to a new CSV file\n",
    "final_merged_df.to_csv('First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as 'First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec9ac9-a6c5-488b-b3ed-b22ea8e8e08c",
   "metadata": {},
   "source": [
    "**Second Step - Topic Knowledge**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032a6b1-8796-4363-8527-5d703c169dc5",
   "metadata": {},
   "source": [
    "Second Step Hierchical Topic Knowledge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc5576f7-9135-4e4f-992b-2a91e428e48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed and the result is saved as 'BERTopic_Second_Step_Second_Level_Topic_Knowledge.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two datasets\n",
    "first_step_df = pd.read_csv('Second_step_clustering_results_labelled.csv')\n",
    "higher_level_topics_df = pd.read_csv('Hierchical_Topics_Second_Level-Topics.csv')\n",
    "\n",
    "# Function to clean and split the topics\n",
    "def clean_and_split_topics(topic_str):\n",
    "    # Remove quotes and split by commas, then strip any extra spaces\n",
    "    topics = [topic.strip().replace('\"', '') for topic in topic_str.split(',')]\n",
    "    return topics\n",
    "\n",
    "# Apply the cleaning function to the 'Human_Readable_Topic' column\n",
    "first_step_df['Human_Readable_Topic'] = first_step_df['Human_Readable_Topic'].str.replace('\"', '', regex=False)\n",
    "higher_level_topics_df['Human_Readable_Topic'] = higher_level_topics_df['Human_Readable_Topic'].apply(clean_and_split_topics)\n",
    "\n",
    "# Explode the 'Human_Readable_Topic' to create a row for each topic\n",
    "higher_level_topics_df = higher_level_topics_df.explode('Human_Readable_Topic')\n",
    "\n",
    "# Merge the two datasets on the cleaned 'Human_Readable_Topic' column\n",
    "merged_df = pd.merge(first_step_df, higher_level_topics_df[['Human_Readable_Topic', 'Higher_Topic_Label']], \n",
    "                     on='Human_Readable_Topic', how='left')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv('BERTopic_Second_Step_Second_Level_Topic_Knowledge.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as 'BERTopic_Second_Step_Second_Level_Topic_Knowledge.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2774f78d-dae4-496b-879c-e5cdb3f4344c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cluster_Label', 'Second_Level_Topic_Label', 'Representation',\n",
       "       'Representative_Docs', 'Highest_Topic_Label',\n",
       "       'Representative_Document'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "first_step_df = pd.read_csv('Second_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv')\n",
    "highest_level_topics_df = pd.read_csv('Hierchical_Topics_Third_Level-Topics.csv')\n",
    "\n",
    "# Function to clean and split the 'Higher_Topic_Label' column\n",
    "def clean_and_split_labels(label_str):\n",
    "    # Split by commas and strip any extra spaces\n",
    "    labels = [label.strip() for label in label_str.split(';')]\n",
    "    return labels\n",
    "\n",
    "# Apply the cleaning and splitting function to the 'Higher_Topic_Label' column\n",
    "highest_level_topics_df['Second_Level_Topic_Label'] = highest_level_topics_df['Second_Level_Topic_Label'].apply(clean_and_split_labels)\n",
    "\n",
    "# Explode the 'Higher_Topic_Label' to create a row for each label\n",
    "highest_level_topics_df = highest_level_topics_df.explode('Second_Level_Topic_Label')\n",
    "\n",
    "# Merge the first step dataset with the highest level topics based on 'Higher_Topic_Label'\n",
    "final_merged_df = pd.merge(first_step_df, highest_level_topics_df[['Second_Level_Topic_Label', 'Highest_Topic_Label']], \n",
    "                           on='Second_Level_Topic_Label', how='left')\n",
    "\n",
    "# Save the final merged dataframe to a new CSV file\n",
    "final_merged_df.to_csv('BERTopic_Second_Step_Third_Level_Topic_Knowledge.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as BERTopic_Second_Step_Third_Level_Topic_Knowledge.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56981ec7-2649-4d31-9b15-8f6f8aa37ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed and the result is saved as 'Second_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "first_step_final_df = pd.read_csv('BERTopic_Second_Step_Third_Level_Topic_Knowledge.csv')\n",
    "final_highest_level_topics_df = pd.read_csv('final_highest_level_topic_labels_with_representatives.csv')\n",
    "\n",
    "# Function to split the 'Highest_Topic_Label' based on semicolons or commas, handle NaN values\n",
    "def split_labels(label_str):\n",
    "    if isinstance(label_str, str):  # Check if the label_str is a string\n",
    "        # Split by semicolon or comma and strip any extra spaces\n",
    "        labels = [label.strip() for label in label_str.split(',')]\n",
    "    else:\n",
    "        labels = [None]  # Return a list with None if label_str is not a string\n",
    "    return labels\n",
    "\n",
    "# Apply the splitting function to the 'Highest_Topic_Label' in the first dataset\n",
    "first_step_final_df['Highest_Topic_Label_Split'] = first_step_final_df['Highest_Topic_Label'].apply(split_labels)\n",
    "\n",
    "# Explode the first dataframe to have one row per label\n",
    "first_step_final_df = first_step_final_df.explode('Highest_Topic_Label_Split')\n",
    "\n",
    "# Explode the final_highest_level_topics_df based on 'Highest_Topic_Label' for proper matching\n",
    "final_highest_level_topics_df['Highest_Topic_Label_Split'] = final_highest_level_topics_df['Highest_Topic_Label'].apply(split_labels)\n",
    "final_highest_level_topics_df = final_highest_level_topics_df.explode('Highest_Topic_Label_Split')\n",
    "\n",
    "# Merge the exploded first dataset with the final highest level topics on 'Highest_Topic_Label_Split'\n",
    "final_merged_df = pd.merge(first_step_final_df, final_highest_level_topics_df[['Highest_Topic_Label_Split', 'Final_Label']], \n",
    "                           left_on='Highest_Topic_Label_Split', right_on='Highest_Topic_Label_Split', how='left')\n",
    "\n",
    "# Drop the auxiliary column used for merging\n",
    "final_merged_df.drop(columns=['Highest_Topic_Label_Split'], inplace=True)\n",
    "\n",
    "# Save the final merged dataframe to a new CSV file\n",
    "final_merged_df.to_csv('Second_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as 'Second_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe61ca59-d49e-416b-b129-d4ac719d4056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed and the result is saved as 'Second_Step_BERTopic_topic_info_labelled_with_Higher_Topic_Label_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two datasets\n",
    "first_step_df = pd.read_csv('Second_step_clustering_results_labelled.csv')\n",
    "higher_level_topics_df = pd.read_csv('higherr_level_topic_labels_with_representatives.csv')\n",
    "\n",
    "# Function to clean and split the topics\n",
    "def clean_and_split_topics(topic_str):\n",
    "    # Remove quotes and split by commas, then strip any extra spaces\n",
    "    topics = [topic.strip().replace('\"', '') for topic in topic_str.split(',')]\n",
    "    return topics\n",
    "\n",
    "# Apply the cleaning function to the 'Human_Readable_Topic' column\n",
    "first_step_df['Human_Readable_Topic'] = first_step_df['Human_Readable_Topic'].str.replace('\"', '', regex=False)\n",
    "higher_level_topics_df['Human_Readable_Topic'] = higher_level_topics_df['Human_Readable_Topic'].apply(clean_and_split_topics)\n",
    "\n",
    "# Explode the 'Human_Readable_Topic' to create a row for each topic\n",
    "higher_level_topics_df = higher_level_topics_df.explode('Human_Readable_Topic')\n",
    "\n",
    "# Merge the two datasets on the cleaned 'Human_Readable_Topic' column\n",
    "merged_df = pd.merge(first_step_df, higher_level_topics_df[['Human_Readable_Topic', 'Higher_Topic_Label']], \n",
    "                     on='Human_Readable_Topic', how='left')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv('Second_Step_BERTopic_topic_info_labelled_with_Higher_Topic_Label_cleaned.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as 'Second_Step_BERTopic_topic_info_labelled_with_Higher_Topic_Label_cleaned.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42b90f-e8ff-4954-9f1d-af466bc5e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assign the Highest Topic Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94af861-cb97-4bec-876e-0d8853d44eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed and the result is saved as 'Second_Step_BERTopic_topic_info_labelled_with_Highest_Topic_Label_final.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "first_step_df = pd.read_csv('Second_Step_BERTopic_topic_info_labelled_with_Higher_Topic_Label_cleaned.csv')\n",
    "highest_level_topics_df = pd.read_csv('highest_level_topic_labels_with_representatives.csv')\n",
    "\n",
    "# Function to clean and split the 'Higher_Topic_Label' column\n",
    "def clean_and_split_labels(label_str):\n",
    "    # Split by commas and strip any extra spaces\n",
    "    labels = [label.strip() for label in label_str.split(';')]\n",
    "    return labels\n",
    "\n",
    "# Apply the cleaning and splitting function to the 'Higher_Topic_Label' column\n",
    "highest_level_topics_df['Higher_Topic_Label'] = highest_level_topics_df['Higher_Topic_Label'].apply(clean_and_split_labels)\n",
    "\n",
    "# Explode the 'Higher_Topic_Label' to create a row for each label\n",
    "highest_level_topics_df = highest_level_topics_df.explode('Higher_Topic_Label')\n",
    "\n",
    "# Merge the first step dataset with the highest level topics based on 'Higher_Topic_Label'\n",
    "final_merged_df = pd.merge(first_step_df, highest_level_topics_df[['Higher_Topic_Label', 'Highest_Topic_Label']], \n",
    "                           on='Higher_Topic_Label', how='left')\n",
    "\n",
    "# Save the final merged dataframe to a new CSV file\n",
    "final_merged_df.to_csv('Second_Step_BERTopic_topic_info_labelled_with_Highest_Topic_Label_final.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as 'Second_Step_BERTopic_topic_info_labelled_with_Highest_Topic_Label_final.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8d2e9-07db-4b5d-91b5-ec687f8eee80",
   "metadata": {},
   "source": [
    "Assign the Final Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a934fabc-676f-4a2a-be1c-ecaa009131c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed and the result is saved as 'First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "first_step_final_df = pd.read_csv('First_Step_BERTopic_topic_info_labelled_with_Highest_Topic_Label_final.csv')\n",
    "final_highest_level_topics_df = pd.read_csv('final_highest_level_topic_labels_with_representatives.csv')\n",
    "\n",
    "# Merge the first step dataset with the final highest level topics based on 'Highest_Topic_Label'\n",
    "final_merged_df = pd.merge(first_step_final_df, final_highest_level_topics_df[['Highest_Topic_Label', 'Final_Label']], \n",
    "                           on='Highest_Topic_Label', how='left')\n",
    "\n",
    "# Save the final merged dataframe to a new CSV file\n",
    "final_merged_df.to_csv('First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as 'First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "693a6485-07a7-47af-b82c-95693bcdd4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed and the result is saved as 'First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "first_step_final_df = pd.read_csv('First_Step_BERTopic_topic_info_labelled_with_Highest_Topic_Label_final.csv')\n",
    "final_highest_level_topics_df = pd.read_csv('final_highest_level_topic_labels_with_representatives.csv')\n",
    "\n",
    "# Function to split the 'Highest_Topic_Label' based on semicolons or commas, handle NaN values\n",
    "def split_labels(label_str):\n",
    "    if isinstance(label_str, str):  # Check if the label_str is a string\n",
    "        # Split by semicolon and strip any extra spaces\n",
    "        labels = [label.strip() for label in label_str.split(';')]\n",
    "    else:\n",
    "        labels = [None]  # Return a list with None if label_str is not a string\n",
    "    return labels\n",
    "\n",
    "# Apply the splitting function to the 'Highest_Topic_Label' in the first dataset\n",
    "first_step_final_df['Highest_Topic_Label_Split'] = first_step_final_df['Highest_Topic_Label'].apply(split_labels)\n",
    "\n",
    "# Explode the first dataframe to have one row per label\n",
    "first_step_final_df = first_step_final_df.explode('Highest_Topic_Label_Split')\n",
    "\n",
    "# Merge the exploded first dataset with the final highest level topics on 'Highest_Topic_Label_Split'\n",
    "final_merged_df = pd.merge(first_step_final_df, final_highest_level_topics_df[['Highest_Topic_Label', 'Final_Label']], \n",
    "                           left_on='Highest_Topic_Label_Split', right_on='Highest_Topic_Label', how='left')\n",
    "\n",
    "# Drop the auxiliary column used for merging\n",
    "final_merged_df.drop(columns=['Highest_Topic_Label_Split'], inplace=True)\n",
    "\n",
    "# Save the final merged dataframe to a new CSV file\n",
    "final_merged_df.to_csv('First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as 'First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "777d2fa7-c3be-49b8-bac6-4ba017ed9358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed and the result is saved as 'First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "first_step_final_df = pd.read_csv('First_Step_BERTopic_topic_info_labelled_with_Highest_Topic_Label_final.csv')\n",
    "final_highest_level_topics_df = pd.read_csv('final_highest_level_topic_labels_with_representatives.csv')\n",
    "\n",
    "# Function to split the 'Highest_Topic_Label' based on semicolons or commas, handle NaN values\n",
    "def split_labels(label_str):\n",
    "    if isinstance(label_str, str):  # Check if the label_str is a string\n",
    "        # Split by semicolon or comma and strip any extra spaces\n",
    "        labels = [label.strip() for label in label_str.split(',')]\n",
    "    else:\n",
    "        labels = [None]  # Return a list with None if label_str is not a string\n",
    "    return labels\n",
    "\n",
    "# Apply the splitting function to the 'Highest_Topic_Label' in the first dataset\n",
    "first_step_final_df['Highest_Topic_Label_Split'] = first_step_final_df['Highest_Topic_Label'].apply(split_labels)\n",
    "\n",
    "# Explode the first dataframe to have one row per label\n",
    "first_step_final_df = first_step_final_df.explode('Highest_Topic_Label_Split')\n",
    "\n",
    "# Explode the final_highest_level_topics_df based on 'Highest_Topic_Label' for proper matching\n",
    "final_highest_level_topics_df['Highest_Topic_Label_Split'] = final_highest_level_topics_df['Highest_Topic_Label'].apply(split_labels)\n",
    "final_highest_level_topics_df = final_highest_level_topics_df.explode('Highest_Topic_Label_Split')\n",
    "\n",
    "# Merge the exploded first dataset with the final highest level topics on 'Highest_Topic_Label_Split'\n",
    "final_merged_df = pd.merge(first_step_final_df, final_highest_level_topics_df[['Highest_Topic_Label_Split', 'Final_Label']], \n",
    "                           left_on='Highest_Topic_Label_Split', right_on='Highest_Topic_Label_Split', how='left')\n",
    "\n",
    "# Drop the auxiliary column used for merging\n",
    "final_merged_df.drop(columns=['Highest_Topic_Label_Split'], inplace=True)\n",
    "\n",
    "# Save the final merged dataframe to a new CSV file\n",
    "final_merged_df.to_csv('First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as 'First_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2ffaa63-1f4a-4072-956c-0df163a613fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed and the result is saved as 'Second_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "first_step_final_df = pd.read_csv('Second_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv')\n",
    "final_highest_level_topics_df = pd.read_csv('final_highest_level_topic_labels_with_representatives.csv')\n",
    "\n",
    "# Function to split the 'Highest_Topic_Label' based on semicolons or commas, handle NaN values\n",
    "def split_labels(label_str):\n",
    "    if isinstance(label_str, str):  # Check if the label_str is a string\n",
    "        # Split by semicolon or comma and strip any extra spaces\n",
    "        labels = [label.strip() for label in label_str.split(',')]\n",
    "    else:\n",
    "        labels = [None]  # Return a list with None if label_str is not a string\n",
    "    return labels\n",
    "\n",
    "# Apply the splitting function to the 'Highest_Topic_Label' in the first dataset\n",
    "first_step_final_df['Highest_Topic_Label_Split'] = first_step_final_df['Highest_Topic_Label'].apply(split_labels)\n",
    "\n",
    "# Explode the first dataframe to have one row per label\n",
    "first_step_final_df = first_step_final_df.explode('Highest_Topic_Label_Split')\n",
    "\n",
    "# Explode the final_highest_level_topics_df based on 'Highest_Topic_Label' for proper matching\n",
    "final_highest_level_topics_df['Highest_Topic_Label_Split'] = final_highest_level_topics_df['Highest_Topic_Label'].apply(split_labels)\n",
    "final_highest_level_topics_df = final_highest_level_topics_df.explode('Highest_Topic_Label_Split')\n",
    "\n",
    "# Merge the exploded first dataset with the final highest level topics on 'Highest_Topic_Label_Split'\n",
    "final_merged_df = pd.merge(first_step_final_df, final_highest_level_topics_df[['Highest_Topic_Label_Split', 'Final_Label']], \n",
    "                           left_on='Highest_Topic_Label_Split', right_on='Highest_Topic_Label_Split', how='left')\n",
    "\n",
    "# Drop the auxiliary column used for merging\n",
    "final_merged_df.drop(columns=['Highest_Topic_Label_Split'], inplace=True)\n",
    "\n",
    "# Save the final merged dataframe to a new CSV file\n",
    "final_merged_df.to_csv('Second_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv', index=False)\n",
    "\n",
    "print(\"Merging completed and the result is saved as 'Second_Step_BERTopic_topic_info_labelled_with_Final_Label_Merged.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c0ffba-3a54-4da2-a196-d5309f6c5464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
