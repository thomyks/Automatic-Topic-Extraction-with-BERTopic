{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f6f2dc-da70-4b6a-832e-f119d72d64d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'Second_step_clustering_BERTopic_results.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "documents = data['text']\n",
    "# Preprocess documents\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "processed_docs = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Create a dictionary and corpus required for Gensim\n",
    "dictionary = corpora.Dictionary(processed_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Extract topics\n",
    "topic_representations = data.groupby('Topic Label')['Second_Step_Topic_Keywords'].apply(lambda x: x.iloc[0].split(', '))\n",
    "topics = topic_representations.tolist()\n",
    "topic_ids = topic_representations.index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fab2d5-4efc-4728-bc7b-e93493959430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'Second_step_clustering_BERTopic_results.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "data_filtered = data[(data['Topic Label'] >= 100) & (data['Topic Label'] <= 200)]\n",
    "\n",
    "# Example: Assuming you have a separate list of documents\n",
    "# Replace this with your actual documents\n",
    "documents = data['text']\n",
    "\n",
    "# Preprocess documents\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "processed_docs = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Create a dictionary and corpus required for Gensim\n",
    "dictionary = corpora.Dictionary(processed_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Filter topics with IDs between 10 and 30\n",
    "data_filtered = data[(data['Topic Label'] >= 100) & (data['Topic Label'] <= 200)]\n",
    "\n",
    "# Extract topics after filtering\n",
    "topic_representations = data_filtered.groupby('Topic Label')['Second_Step_Topic_Keywords'].apply(lambda x: x.iloc[0].split(', '))\n",
    "topics = topic_representations.tolist()\n",
    "topic_ids = topic_representations.index.tolist()\n",
    "\n",
    "# Define coherence measures you want to compute\n",
    "coherence_measures = ['c_v', 'u_mass', 'c_npmi']\n",
    "\n",
    "# Initialize a dictionary to store coherence scores per topic\n",
    "per_topic_coherence = {measure: [] for measure in coherence_measures}\n",
    "\n",
    "for topic in topics:\n",
    "    # Create a list containing just the current topic\n",
    "    current_topic = [topic]\n",
    "    \n",
    "    # Initialize the CoherenceModel for the current topic\n",
    "    coherence_model_cv = CoherenceModel(topics=current_topic, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "#     coherence_model_umass = CoherenceModel(topics=current_topic, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "#     coherence_model_cnpmi = CoherenceModel(topics=current_topic, texts=processed_docs, dictionary=dictionary, coherence='c_npmi')\n",
    "    \n",
    "    # Compute coherence scores\n",
    "    coherence_cv = coherence_model_cv.get_coherence()\n",
    "#     coherence_umass = coherence_model_umass.get_coherence()\n",
    "#     coherence_cnpmi = coherence_model_cnpmi.get_coherence()\n",
    "    \n",
    "    # Append scores to the dictionary\n",
    "    per_topic_coherence['c_v'].append(coherence_cv)\n",
    "    # per_topic_coherence['u_mass'].append(coherence_umass)\n",
    "    # per_topic_coherence['c_npmi'].append(coherence_cnpmi)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results = pd.DataFrame({\n",
    "    \"Topic\": topic_ids,\n",
    "    \"Keywords\": topic_representations.values,\n",
    "    \"Coherence c_v\": per_topic_coherence['c_v'],\n",
    "    # \"Coherence u_mass\": per_topic_coherence['u_mass'],\n",
    "    # \"Coherence c_npmi\": per_topic_coherence['c_npmi'],\n",
    "})\n",
    "\n",
    "# Calculate the average coherence scores for topics between 10 and 30\n",
    "average_coherence_cv = results[\"Coherence c_v\"].mean()\n",
    "# average_coherence_umass = results[\"Coherence u_mass\"].mean()\n",
    "# average_coherence_cnpmi = results[\"Coherence c_npmi\"].mean()\n",
    "\n",
    "# Display overall and per-topic coherence scores\n",
    "print(results)\n",
    "print(f\"\\nAverage Coherence c_v (Topics 10-30): {average_coherence_cv}\")\n",
    "print(f\"Average Coherence u_mass (Topics 10-30): {average_coherence_umass}\")\n",
    "print(f\"Average Coherence c_npmi (Topics 10-30): {average_coherence_cnpmi}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e8d9b-5580-42ad-a565-3d2d5ff9dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'Second_step_clustering_BERTopic_results.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "data_filtered = data[(data['Topic Label'] >= 100) & (data['Topic Label'] <= 200)]\n",
    "\n",
    "# Example: Assuming you have a separate list of documents\n",
    "documents = data['text']\n",
    "\n",
    "# Preprocess documents\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "processed_docs = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Create a dictionary and corpus required for Gensim\n",
    "dictionary = corpora.Dictionary(processed_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Filter topics with IDs between 10 and 30\n",
    "data_filtered = data[(data['Topic Label'] >= 100) & (data['Topic Label'] <= 200)]\n",
    "\n",
    "# Extract topics after filtering\n",
    "topic_representations = data_filtered.groupby('Topic Label')['Second_Step_Topic_Keywords'].apply(lambda x: x.iloc[0].split(', '))\n",
    "topics = topic_representations.tolist()\n",
    "topic_ids = topic_representations.index.tolist()\n",
    "\n",
    "# Calculate Topic Diversity\n",
    "def calculate_topic_diversity(topics):\n",
    "    unique_words = set()\n",
    "    total_words = 0\n",
    "\n",
    "    for topic in topics:\n",
    "        unique_words.update(topic)  # Add words to the unique set\n",
    "        total_words += len(topic)   # Count total words in all topics\n",
    "\n",
    "    # Topic diversity is the proportion of unique words to total words\n",
    "    topic_diversity = len(unique_words) / total_words\n",
    "    return topic_diversity\n",
    "\n",
    "# Calculate topic diversity\n",
    "topic_diversity = calculate_topic_diversity(topics)\n",
    "\n",
    "# Define coherence measures you want to compute\n",
    "coherence_measures = ['c_v', 'u_mass', 'c_npmi']\n",
    "\n",
    "# Initialize a dictionary to store coherence scores per topic\n",
    "per_topic_coherence = {measure: [] for measure in coherence_measures}\n",
    "\n",
    "for topic in topics:\n",
    "    # Create a list containing just the current topic\n",
    "    current_topic = [topic]\n",
    "    \n",
    "    # Initialize the CoherenceModel for the current topic\n",
    "    coherence_model_cv = CoherenceModel(topics=current_topic, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_model_umass = CoherenceModel(topics=current_topic, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "    coherence_model_cnpmi = CoherenceModel(topics=current_topic, texts=processed_docs, dictionary=dictionary, coherence='c_npmi')\n",
    "    \n",
    "    # Compute coherence scores\n",
    "    coherence_cv = coherence_model_cv.get_coherence()\n",
    "    coherence_umass = coherence_model_umass.get_coherence()\n",
    "    coherence_cnpmi = coherence_model_cnpmi.get_coherence()\n",
    "    \n",
    "    # Append scores to the dictionary\n",
    "    per_topic_coherence['c_v'].append(coherence_cv)\n",
    "    per_topic_coherence['u_mass'].append(coherence_umass)\n",
    "    per_topic_coherence['c_npmi'].append(coherence_cnpmi)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results = pd.DataFrame({\n",
    "    \"Topic\": topic_ids,\n",
    "    \"Keywords\": topic_representations.values,\n",
    "    \"Coherence c_v\": per_topic_coherence['c_v'],\n",
    "    \"Coherence u_mass\": per_topic_coherence['u_mass'],\n",
    "    \"Coherence c_npmi\": per_topic_coherence['c_npmi'],\n",
    "})\n",
    "\n",
    "# Calculate the average coherence scores for topics between 10 and 30\n",
    "average_coherence_cv = results[\"Coherence c_v\"].mean()\n",
    "average_coherence_umass = results[\"Coherence u_mass\"].mean()\n",
    "average_coherence_cnpmi = results[\"Coherence c_npmi\"].mean()\n",
    "\n",
    "# Display overall and per-topic coherence scores\n",
    "print(results)\n",
    "print(f\"\\nAverage Coherence c_v (Topics 10-30): {average_coherence_cv}\")\n",
    "print(f\"Average Coherence u_mass (Topics 10-30): {average_coherence_umass}\")\n",
    "print(f\"Average Coherence c_npmi (Topics 10-30): {average_coherence_cnpmi}\")\n",
    "\n",
    "# Display the topic diversity score\n",
    "print(f\"\\nTopic Diversity: {topic_diversity}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c327da45-17ff-4f3e-9ade-0723c32defff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42980769230769234"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e3e5e-6886-486d-874d-e213aaf544da",
   "metadata": {},
   "source": [
    "Only the Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1478ad7-52b1-46ec-aee0-d6c91ce24c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Diversity: 0.42980769230769234\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'Second_step_clustering_BERTopic_results.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "data_filtered = data[(data['Topic Label'] >= 1) & (data['Topic Label'] <= 350)]\n",
    "\n",
    "# Example: Assuming you have a separate list of documents\n",
    "documents = data['text']\n",
    "\n",
    "# Preprocess documents\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "processed_docs = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Filter topics with IDs between 100 and 200\n",
    "data_filtered = data[(data['Topic Label'] >= 1) & (data['Topic Label'] <= 350)]\n",
    "\n",
    "# Extract topics after filtering\n",
    "topic_representations = data_filtered.groupby('Topic Label')['Second_Step_Topic_Keywords'].apply(lambda x: x.iloc[0].split(', '))\n",
    "topics = topic_representations.tolist()\n",
    "\n",
    "# Calculate Topic Diversity\n",
    "def calculate_topic_diversity(topics):\n",
    "    unique_words = set()\n",
    "    total_words = 0\n",
    "\n",
    "    for topic in topics:\n",
    "        unique_words.update(topic)  # Add words to the unique set\n",
    "        total_words += len(topic)   # Count total words in all topics\n",
    "\n",
    "    # Topic diversity is the proportion of unique words to total words\n",
    "    topic_diversity = len(unique_words) / total_words\n",
    "    return topic_diversity\n",
    "\n",
    "# Calculate topic diversity\n",
    "topic_diversity = calculate_topic_diversity(topics)\n",
    "\n",
    "# Display the topic diversity score\n",
    "print(f\"\\nTopic Diversity: {topic_diversity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd4efea3-bd49-4f1f-9f5a-3964c856f6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic labels and diversity scores have been saved to 'topic_labels_and_diversity_scores.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'Second_step_clustering_BERTopic_results.csv'  # Replace with your actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter topics where Topic Label is between 1 and 350\n",
    "data_filtered = data[(data['Topic Label'] >= 1) & (data['Topic Label'] <= 350)]\n",
    "\n",
    "# Example: Assuming you have a separate list of documents\n",
    "documents = data['text']\n",
    "\n",
    "# Preprocess documents\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "processed_docs = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Extract topics after filtering\n",
    "topic_representations = data_filtered.groupby('Topic Label')['Second_Step_Topic_Keywords'].apply(lambda x: x.iloc[0].split(', '))\n",
    "\n",
    "# Calculate Topic Diversity\n",
    "def calculate_topic_diversity(topic):\n",
    "    unique_words = set(topic)  # Add words to the unique set\n",
    "    total_words = len(topic)   # Count total words in the topic\n",
    "    # Topic diversity is the proportion of unique words to total words\n",
    "    topic_diversity = len(unique_words) / total_words\n",
    "    return topic_diversity\n",
    "\n",
    "# Calculate topic diversity for each topic\n",
    "topic_diversity_scores = topic_representations.apply(calculate_topic_diversity)\n",
    "\n",
    "# Save Topic Labels and Diversity Scores to CSV\n",
    "output_df = pd.DataFrame({\n",
    "    'Topic Label': topic_representations.index,\n",
    "    'Diversity Score': topic_diversity_scores\n",
    "})\n",
    "\n",
    "\n",
    "print(\"Topic labels and diversity scores have been saved to 'topic_labels_and_diversity_scores.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbd25aea-b61c-4704-a78b-1c24ef009708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Diversity: 0.42980769230769234\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14a64633-5c52-4ab0-87e9-f5df759596fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process AccumulatingWorker-24321:\n",
      "Process AccumulatingWorker-24387:\n",
      "Process AccumulatingWorker-24380:\n",
      "Process AccumulatingWorker-24413:\n",
      "Process AccumulatingWorker-24361:\n",
      "Process AccumulatingWorker-24386:\n",
      "Process AccumulatingWorker-24394:\n",
      "Process AccumulatingWorker-24390:\n",
      "Process AccumulatingWorker-24388:\n",
      "Process AccumulatingWorker-24378:\n",
      "Process AccumulatingWorker-24383:\n",
      "Process AccumulatingWorker-24381:\n",
      "Process AccumulatingWorker-24391:\n",
      "Process AccumulatingWorker-24385:\n",
      "Process AccumulatingWorker-24395:\n",
      "Process AccumulatingWorker-24402:\n",
      "Process AccumulatingWorker-24400:\n",
      "Process AccumulatingWorker-24408:\n",
      "Process AccumulatingWorker-24411:\n",
      "Process AccumulatingWorker-24393:\n",
      "Process AccumulatingWorker-24409:\n",
      "Process AccumulatingWorker-24366:\n",
      "Process AccumulatingWorker-24363:\n",
      "Process AccumulatingWorker-24365:\n",
      "Process AccumulatingWorker-24367:\n",
      "Process AccumulatingWorker-24368:\n",
      "Process AccumulatingWorker-24412:\n",
      "Process AccumulatingWorker-24410:\n",
      "Process AccumulatingWorker-24369:\n",
      "Process AccumulatingWorker-24414:\n",
      "Process AccumulatingWorker-24360:\n",
      "Process AccumulatingWorker-24362:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process AccumulatingWorker-24356:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process AccumulatingWorker-24354:\n",
      "Process AccumulatingWorker-24355:\n",
      "Process AccumulatingWorker-24346:\n",
      "Process AccumulatingWorker-24336:\n",
      "Process AccumulatingWorker-24337:\n",
      "Process AccumulatingWorker-24343:\n",
      "Process AccumulatingWorker-24330:\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "Process AccumulatingWorker-24359:\n",
      "Process AccumulatingWorker-24348:\n",
      "Process AccumulatingWorker-24357:\n",
      "Process AccumulatingWorker-24353:\n",
      "Process AccumulatingWorker-24370:\n",
      "Process AccumulatingWorker-24347:\n",
      "Process AccumulatingWorker-24351:\n",
      "Process AccumulatingWorker-24372:\n",
      "Process AccumulatingWorker-24358:\n",
      "Process AccumulatingWorker-24375:\n",
      "Process AccumulatingWorker-24374:\n",
      "Process AccumulatingWorker-24376:\n",
      "Process AccumulatingWorker-24352:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process AccumulatingWorker-24323:\n",
      "Process AccumulatingWorker-24325:\n",
      "Process AccumulatingWorker-24326:\n",
      "Process AccumulatingWorker-24328:\n",
      "Process AccumulatingWorker-24329:\n",
      "Process AccumulatingWorker-24334:\n",
      "Process AccumulatingWorker-24324:\n",
      "Process AccumulatingWorker-24332:\n",
      "Process AccumulatingWorker-24333:\n",
      "Process AccumulatingWorker-24322:\n",
      "Process AccumulatingWorker-24338:\n",
      "Process AccumulatingWorker-24331:\n",
      "Traceback (most recent call last):\n",
      "Process AccumulatingWorker-24339:\n",
      "Process AccumulatingWorker-24350:\n",
      "Process AccumulatingWorker-24349:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m coherence_model_cnpmi \u001b[38;5;241m=\u001b[39m CoherenceModel(topics\u001b[38;5;241m=\u001b[39mcurrent_topic, texts\u001b[38;5;241m=\u001b[39mprocessed_docs, dictionary\u001b[38;5;241m=\u001b[39mdictionary, coherence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_npmi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Compute coherence scores\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m coherence_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcoherence_model_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m coherence_umass \u001b[38;5;241m=\u001b[39m coherence_model_umass\u001b[38;5;241m.\u001b[39mget_coherence()\n\u001b[1;32m     21\u001b[0m coherence_cnpmi \u001b[38;5;241m=\u001b[39m coherence_model_cnpmi\u001b[38;5;241m.\u001b[39mget_coherence()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/models/coherencemodel.py:614\u001b[0m, in \u001b[0;36mCoherenceModel.get_coherence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_coherence\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;124;03m\"\"\"Get coherence value based on pipeline parameters.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \n\u001b[1;32m    608\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m     confirmed_measures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence_per_topic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_measures(confirmed_measures)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/models/coherencemodel.py:574\u001b[0m, in \u001b[0;36mCoherenceModel.get_coherence_per_topic\u001b[0;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[1;32m    572\u001b[0m     segmented_topics \u001b[38;5;241m=\u001b[39m measure\u001b[38;5;241m.\u001b[39mseg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopics)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmented_topics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(with_std\u001b[38;5;241m=\u001b[39mwith_std, with_support\u001b[38;5;241m=\u001b[39mwith_support)\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;129;01min\u001b[39;00m BOOLEAN_DOCUMENT_BASED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_w2v\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/models/coherencemodel.py:546\u001b[0m, in \u001b[0;36mCoherenceModel.estimate_probabilities\u001b[0;34m(self, segmented_topics)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_w2v\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    544\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeyed_vectors\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/topic_coherence/probability_estimation.py:156\u001b[0m, in \u001b[0;36mp_boolean_sliding_window\u001b[0;34m(texts, segmented_topics, dictionary, window_size, processes)\u001b[0m\n\u001b[1;32m    154\u001b[0m     accumulator \u001b[38;5;241m=\u001b[39m ParallelWordOccurrenceAccumulator(processes, top_ids, dictionary)\n\u001b[1;32m    155\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to estimate probabilities from sliding windows\u001b[39m\u001b[38;5;124m\"\u001b[39m, accumulator)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maccumulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/topic_coherence/text_analysis.py:445\u001b[0m, in \u001b[0;36mParallelWordOccurrenceAccumulator.accumulate\u001b[0;34m(self, texts, window_size)\u001b[0m\n\u001b[1;32m    442\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats accumulation interrupted; <= \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m documents processed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_docs)\n\u001b[1;32m    443\u001b[0m     interrupted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m accumulators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_accumulators(accumulators)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/topic_coherence/text_analysis.py:522\u001b[0m, in \u001b[0;36mParallelWordOccurrenceAccumulator.terminate_workers\u001b[0;34m(self, input_q, output_q, workers, interrupted)\u001b[0m\n\u001b[1;32m    520\u001b[0m accumulators \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accumulators) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(workers):\n\u001b[0;32m--> 522\u001b[0m     accumulators\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutput_q\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    523\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m accumulators retrieved from output queue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(accumulators))\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m worker \u001b[38;5;129;01min\u001b[39;00m workers:\n",
      "File \u001b[0;32m/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cvmfs/sys.hpc.itc.rwth-aachen.de/jupyter/clients/pytorch-gpu/lib/python3.9/site-packages/scipy/sparse/_base.py:749\u001b[0m, in \u001b[0;36mspmatrix.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m--> 749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_array:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Define coherence measures you want to compute\n",
    "coherence_measures = ['c_v', 'u_mass', 'c_npmi']\n",
    "\n",
    "# Initialize a dictionary to store coherence scores per topic\n",
    "per_topic_coherence = {measure: [] for measure in coherence_measures}\n",
    "\n",
    "for topic in topics:\n",
    "    # Create a list containing just the current topic\n",
    "    current_topic = [topic]\n",
    "    \n",
    "    # Initialize the CoherenceModel for the current topic\n",
    "    coherence_model_cv = CoherenceModel(topics=current_topic, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_model_umass = CoherenceModel(topics=current_topic, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "    coherence_model_cnpmi = CoherenceModel(topics=current_topic, texts=processed_docs, dictionary=dictionary, coherence='c_npmi')\n",
    "    \n",
    "    # Compute coherence scores\n",
    "    coherence_cv = coherence_model_cv.get_coherence()\n",
    "    coherence_umass = coherence_model_umass.get_coherence()\n",
    "    coherence_cnpmi = coherence_model_cnpmi.get_coherence()\n",
    "    \n",
    "    # Append scores to the dictionary\n",
    "    per_topic_coherence['c_v'].append(coherence_cv)\n",
    "    per_topic_coherence['u_mass'].append(coherence_umass)\n",
    "    per_topic_coherence['c_npmi'].append(coherence_cnpmi)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results = pd.DataFrame({\n",
    "    \"Topic\": topic_ids,\n",
    "    \"Keywords\": topic_representations.values,\n",
    "    \"Coherence c_v\": per_topic_coherence['c_v'],\n",
    "    \"Coherence u_mass\": per_topic_coherence['u_mass'],\n",
    "    \"Coherence c_npmi\": per_topic_coherence['c_npmi'],\n",
    "})\n",
    "\n",
    "# Display overall and per-topic coherence scores\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda6420-205a-44b5-892c-5aa7bda6f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results_evaluation_second_step.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a836a400-1d12-48b8-863e-1fdd4df2c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average coherence scores\n",
    "average_coherence_cv = results[\"Coherence c_v\"].mean()\n",
    "average_coherence_umass = results[\"Coherence u_mass\"].mean()\n",
    "average_coherence_cnpmi = results[\"Coherence c_npmi\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc04b25-0513-439e-810e-4b62981bf4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_coherence_cv\n",
    "# average_coherence_cnpmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867fbcc-598c-4352-8588-2b12068ca9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yc656703/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'k-100-Second_step_clustering_BERTopic_results.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "data = data[(data['Topic'] >= 30) & (data['Topic'] <= 60)]\n",
    "\n",
    "# Example: Assuming you have a separate list of documents\n",
    "# Replace this with your actual documents\n",
    "documents = data['abstract']\n",
    "\n",
    "# Preprocess documents\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "processed_docs = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Create a dictionary and corpus required for Gensim\n",
    "dictionary = corpora.Dictionary(processed_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Filter topics with IDs between 10 and 30\n",
    "data_filtered = data[(data['Topic'] >= 30) & (data['Topic'] <= 60)]\n",
    "\n",
    "# Extract topics after filtering\n",
    "topic_representations = data_filtered.groupby('Topic')['Second_Step_Topic_Representation'].apply(lambda x: x.iloc[0].split(', '))\n",
    "topics = topic_representations.tolist()\n",
    "topic_ids = topic_representations.index.tolist()\n",
    "\n",
    "# Define coherence measures you want to compute\n",
    "coherence_measures = ['c_v', 'u_mass', 'c_npmi']\n",
    "\n",
    "# Initialize a dictionary to store coherence scores per topic\n",
    "per_topic_coherence = {measure: [] for measure in coherence_measures}\n",
    "\n",
    "for topic in topics:\n",
    "    # Create a list containing just the current topic\n",
    "    current_topic = [topic]\n",
    "    \n",
    "    # Initialize the CoherenceModel for the current topic\n",
    "    coherence_model_cv = CoherenceModel(topics=current_topic, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_model_umass = CoherenceModel(topics=current_topic, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "    coherence_model_cnpmi = CoherenceModel(topics=current_topic, texts=processed_docs, dictionary=dictionary, coherence='c_npmi')\n",
    "    \n",
    "    # Compute coherence scores\n",
    "    coherence_cv = coherence_model_cv.get_coherence()\n",
    "    coherence_umass = coherence_model_umass.get_coherence()\n",
    "    coherence_cnpmi = coherence_model_cnpmi.get_coherence()\n",
    "    \n",
    "    # Append scores to the dictionary\n",
    "    per_topic_coherence['c_v'].append(coherence_cv)\n",
    "    per_topic_coherence['u_mass'].append(coherence_umass)\n",
    "    per_topic_coherence['c_npmi'].append(coherence_cnpmi)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results = pd.DataFrame({\n",
    "    \"Topic\": topic_ids,\n",
    "    \"Keywords\": topic_representations.values,\n",
    "    \"Coherence c_v\": per_topic_coherence['c_v'],\n",
    "    \"Coherence u_mass\": per_topic_coherence['u_mass'],\n",
    "    \"Coherence c_npmi\": per_topic_coherence['c_npmi'],\n",
    "})\n",
    "\n",
    "# Calculate the average coherence scores for topics between 10 and 30\n",
    "average_coherence_cv = results[\"Coherence c_v\"].mean()\n",
    "average_coherence_umass = results[\"Coherence u_mass\"].mean()\n",
    "average_coherence_cnpmi = results[\"Coherence c_npmi\"].mean()\n",
    "\n",
    "# Display overall and per-topic coherence scores\n",
    "print(results)\n",
    "print(f\"\\nAverage Coherence c_v (Topics 10-30): {average_coherence_cv}\")\n",
    "print(f\"Average Coherence u_mass (Topics 10-30): {average_coherence_umass}\")\n",
    "print(f\"Average Coherence c_npmi (Topics 10-30): {average_coherence_cnpmi}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
